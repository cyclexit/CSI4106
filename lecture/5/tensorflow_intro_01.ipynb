{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tensors:\n",
    "Tensors can be considered as a general representation for multidimensional arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "0\n",
      "(4,)\n",
      "1\n",
      "(2, 2)\n",
      "2\n",
      "(2, 2, 2)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# rank = axes = ndim\n",
    "# rank-0 tensors\n",
    "x_0 = np.array(12)\n",
    "print(x_0.shape)\n",
    "print(x_0.ndim)\n",
    "\n",
    "# rank-1 tensors\n",
    "x_1 = np.array([1, 2, 3, 4])\n",
    "print(x_1.shape)\n",
    "print(x_1.ndim)\n",
    "\n",
    "# rank-2 tensors\n",
    "x_2 = np.array([[1, 2], [3, 4]])\n",
    "print(x_2.shape)\n",
    "print(x_2.ndim)\n",
    "\n",
    "# rank-3 tensors\n",
    "x_3 = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8,]]])\n",
    "print(x_3.shape)\n",
    "print(x_3.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "# output = relu(dot(input, w) + b)\n",
    "# What does ReLU do:\n",
    "# if dot product is < 0 return 0 else output\n",
    "def relu_function(x):\n",
    "    assert len(x.shape) == 2\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] = max(x[i, j], 0)\n",
    "    \n",
    "    return x\n",
    "\n",
    "x = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(relu_function(x))\n",
    "\n",
    "# NOTE: using numpy\n",
    "# z = x + y\n",
    "# z = np.maximum(z, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "# what is broadcasting\n",
    "x = np.array([1, 2, 3])\n",
    "y = np.array([4, 5, 6])\n",
    "\n",
    "z = np.dot(x, y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n",
      "(3, 3)\n",
      "[[48 54 60]]\n",
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "# dot product between a vector and a matrix\n",
    "x = np.array([[1, 2, 3]])\n",
    "y = np.array([[4, 5, 6], [7, 8, 9], [10, 11, 12]])\n",
    "z = np.dot(x, y)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(z)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]]\n",
      "(6, 1)\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "# tensor reshaping\n",
    "x = np.array([[1, 2,], [3, 4], [5, 6]])\n",
    "print(x.shape)\n",
    "\n",
    "x = x.reshape((6, 1))\n",
    "print(x)\n",
    "print(x.shape)\n",
    "x = x.reshape((2, 3))\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(96.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Automatic differentiation:\n",
    "# Capability or obtaining gradients on any number of tensor operations that are differentiable\n",
    "\n",
    "# Stores tensor operations in a form of computational graph\n",
    "x = tf.Variable(2.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    # NOTE: using the calculus power rule\n",
    "    # NOTE: taking the derivative means taking the slope of the function at a given point\n",
    "    y = 3 * x ** 4\n",
    "    # NOTE: using the tape to calculate the gradient of the output\n",
    "    dy_dx = tape.gradient(y, x)\n",
    "\n",
    "print(dy_dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "array([[0.15209198, 0.15209198],\n",
      "       [0.59820557, 0.59820557]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 2.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "# calculating gradients on a list of variables\n",
    "# variables are mutable objects\n",
    "w = tf.Variable(tf.random.uniform((2, 2)))\n",
    "b = tf.Variable(tf.zeros((2, )))\n",
    "x = tf.random.uniform((2, 2))\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = tf.matmul(x, w) + b\n",
    "    # gradients of y with respect to \"w\" and \"b\"\n",
    "    grad_of_y = tape.gradient(y, [w, b])\n",
    "    print(grad_of_y)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcacb1169d0317e97b762e0c1a317633c556cb59cb1017287d7e24b96b766e04"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('csi4106')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
