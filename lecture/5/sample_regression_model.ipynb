{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 25568), started 0:15:35 ago. (Use '!kill 25568' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e3e207f8bfe10b92\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e3e207f8bfe10b92\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                41.0        880.0           129.0   \n",
      "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2    -122.24     37.85                52.0       1467.0           190.0   \n",
      "3    -122.25     37.85                52.0       1274.0           235.0   \n",
      "4    -122.25     37.85                52.0       1627.0           280.0   \n",
      "\n",
      "   population  households  median_income  median_house_value ocean_proximity  \n",
      "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
      "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
      "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
      "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
      "4       565.0       259.0         3.8462            342200.0        NEAR BAY  \n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "df = pd.read_csv('./data/housing.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"income_cat\"] = pd.cut(df[\"median_income\"], bins=[0., 1.5, 3.0, 4.5, 6., np.inf], labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "# stratified(i.e., preserving the percentage of samples under each class) shuffle splitting the dataset\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(df, df[\"income_cat\"]):\n",
    "    strat_train_set = df.loc[train_index]\n",
    "    strat_test_set = df.loc[test_index]\n",
    "\n",
    "# drop the categorical feature as we do not need it anymore\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)\n",
    "\n",
    "data = strat_train_set.drop(\"median_house_value\", axis=1) \n",
    "train_labels = strat_train_set[\"median_house_value\"].to_numpy(copy=True)\n",
    "\n",
    "# creating a pipeline so that you can chain together multiple steps\n",
    "# NOTE: remember that the output from one step will be an inout to the other\n",
    "# you can do these steps seperately and combine but Pipelines are more efficient\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "housing_num = data.drop(\"ocean_proximity\", axis=1)\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "# will be applying tranasformer object to the given subset of data\n",
    "# NOTE: e.g., the \"num_pipeline\" transformer object will be applied on the given set of columns\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ])\n",
    "\n",
    " # sending the data through a chain of transformations\n",
    " # NOTE: the final dataset is a 2D numpy array containg all numerical data\n",
    "train_data = full_pipeline.fit_transform(data)\n",
    "\n",
    "# test the model on test data\n",
    "x_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "test_labels = strat_test_set[\"median_house_value\"].to_numpy(copy=True)\n",
    "\n",
    "test_data = full_pipeline.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "def get_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(256, input_shape=(13,), activation=\"relu\"),\n",
    "        layers.Dense(256, activation=\"relu\"),\n",
    "        layers.Dense(1)  # default linear activation due to the regression task\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard\n",
    "# create directory to store the callback logs\n",
    "d = datetime.datetime.today()\n",
    "timestamp = d.strftime('%Y%m%d_%H%M%S')\n",
    "tensorlog_folder = os.path.join(os.path.curdir, 'logs', timestamp)\n",
    "os.mkdir(tensorlog_folder)\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir=tensorlog_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "516/516 [==============================] - 3s 4ms/step - loss: 53422800896.0000 - mae: 200992.5625 - val_loss: 50249297920.0000 - val_mae: 192756.8906\n",
      "Epoch 2/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 36385001472.0000 - mae: 156280.1875 - val_loss: 22592612352.0000 - val_mae: 114392.3906\n",
      "Epoch 3/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 12354563072.0000 - mae: 80025.2734 - val_loss: 8577631232.0000 - val_mae: 66030.2578\n",
      "Epoch 4/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 6901264896.0000 - mae: 59366.4883 - val_loss: 6660993536.0000 - val_mae: 57017.2383\n",
      "Epoch 5/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 5676717568.0000 - mae: 53651.3125 - val_loss: 5790976512.0000 - val_mae: 53521.6797\n",
      "Epoch 6/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 5088532992.0000 - mae: 51132.9922 - val_loss: 5307537408.0000 - val_mae: 51604.9531\n",
      "Epoch 7/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4791811584.0000 - mae: 49797.7461 - val_loss: 5083250688.0000 - val_mae: 51043.9180\n",
      "Epoch 8/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4658022400.0000 - mae: 49165.8047 - val_loss: 4972487680.0000 - val_mae: 50408.3242\n",
      "Epoch 9/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4581179392.0000 - mae: 48741.9961 - val_loss: 4908326400.0000 - val_mae: 50231.0703\n",
      "Epoch 10/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4534946304.0000 - mae: 48564.4648 - val_loss: 4897853440.0000 - val_mae: 49552.8711\n",
      "Epoch 11/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4502641152.0000 - mae: 48220.4609 - val_loss: 4869788672.0000 - val_mae: 49672.0820\n",
      "Epoch 12/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4463789568.0000 - mae: 48034.7891 - val_loss: 4849550336.0000 - val_mae: 49800.6680\n",
      "Epoch 13/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4448337920.0000 - mae: 47896.4688 - val_loss: 4815050240.0000 - val_mae: 49689.0664\n",
      "Epoch 14/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4429411328.0000 - mae: 47793.9141 - val_loss: 4824575488.0000 - val_mae: 49207.7969\n",
      "Epoch 15/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4408253952.0000 - mae: 47634.2539 - val_loss: 4818763264.0000 - val_mae: 48835.0859\n",
      "Epoch 16/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4382511616.0000 - mae: 47476.1719 - val_loss: 4842036224.0000 - val_mae: 48804.4180\n",
      "Epoch 17/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4372534784.0000 - mae: 47333.3281 - val_loss: 4806230016.0000 - val_mae: 49235.7031\n",
      "Epoch 18/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4363402752.0000 - mae: 47313.7773 - val_loss: 4771113472.0000 - val_mae: 48636.3398\n",
      "Epoch 19/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4349880832.0000 - mae: 47122.9727 - val_loss: 4758646784.0000 - val_mae: 48742.3828\n",
      "Epoch 20/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4333535744.0000 - mae: 47058.3320 - val_loss: 4745194496.0000 - val_mae: 48871.7070\n",
      "Epoch 21/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4321164800.0000 - mae: 47021.0938 - val_loss: 4753704960.0000 - val_mae: 48243.8398\n",
      "Epoch 22/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4311914496.0000 - mae: 46778.3906 - val_loss: 4755314688.0000 - val_mae: 48307.0195\n",
      "Epoch 23/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4295155200.0000 - mae: 46772.4297 - val_loss: 4737612800.0000 - val_mae: 48506.6562\n",
      "Epoch 24/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4287110144.0000 - mae: 46643.7227 - val_loss: 4720391168.0000 - val_mae: 48625.7227\n",
      "Epoch 25/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4280282112.0000 - mae: 46581.8633 - val_loss: 4739736576.0000 - val_mae: 48371.6680\n",
      "Epoch 26/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4275990784.0000 - mae: 46517.4258 - val_loss: 4705050112.0000 - val_mae: 48389.7539\n",
      "Epoch 27/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4265261312.0000 - mae: 46466.3047 - val_loss: 4716613120.0000 - val_mae: 48250.4297\n",
      "Epoch 28/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4254023168.0000 - mae: 46438.7383 - val_loss: 4695749632.0000 - val_mae: 48114.1367\n",
      "Epoch 29/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4245737984.0000 - mae: 46282.1641 - val_loss: 4712211456.0000 - val_mae: 48309.4727\n",
      "Epoch 30/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4241029632.0000 - mae: 46295.2070 - val_loss: 4689519616.0000 - val_mae: 47828.8789\n",
      "Epoch 31/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4230041856.0000 - mae: 46185.9531 - val_loss: 4690597888.0000 - val_mae: 48001.6953\n",
      "Epoch 32/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4221085696.0000 - mae: 46066.7539 - val_loss: 4679736832.0000 - val_mae: 48122.6523\n",
      "Epoch 33/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4215753472.0000 - mae: 46053.7305 - val_loss: 4672347648.0000 - val_mae: 47980.0312\n",
      "Epoch 34/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4210483456.0000 - mae: 45979.0977 - val_loss: 4681538560.0000 - val_mae: 47980.3711\n",
      "Epoch 35/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4201909760.0000 - mae: 45853.2930 - val_loss: 4706734080.0000 - val_mae: 48490.5195\n",
      "Epoch 36/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4200179968.0000 - mae: 45994.8750 - val_loss: 4654987776.0000 - val_mae: 47469.6133\n",
      "Epoch 37/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4193795072.0000 - mae: 45822.4180 - val_loss: 4644624896.0000 - val_mae: 47405.1094\n",
      "Epoch 38/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4183241984.0000 - mae: 45805.2383 - val_loss: 4666334720.0000 - val_mae: 47679.5312\n",
      "Epoch 39/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4182558464.0000 - mae: 45698.6250 - val_loss: 4657937920.0000 - val_mae: 47249.0391\n",
      "Epoch 40/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4176767232.0000 - mae: 45663.7656 - val_loss: 4648588288.0000 - val_mae: 47308.2773\n",
      "Epoch 41/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4167255040.0000 - mae: 45671.0898 - val_loss: 4657350144.0000 - val_mae: 47292.1484\n",
      "Epoch 42/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4161449472.0000 - mae: 45532.9844 - val_loss: 4642250752.0000 - val_mae: 47198.7148\n",
      "Epoch 43/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4157257216.0000 - mae: 45566.9141 - val_loss: 4636785664.0000 - val_mae: 47323.9570\n",
      "Epoch 44/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4145077248.0000 - mae: 45511.4727 - val_loss: 4652064256.0000 - val_mae: 47459.8398\n",
      "Epoch 45/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4147232768.0000 - mae: 45466.9922 - val_loss: 4630617600.0000 - val_mae: 47142.7617\n",
      "Epoch 46/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4135148544.0000 - mae: 45429.6250 - val_loss: 4644711424.0000 - val_mae: 47283.4531\n",
      "Epoch 47/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4139481088.0000 - mae: 45380.3633 - val_loss: 4616284160.0000 - val_mae: 46894.6758\n",
      "Epoch 48/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4132174848.0000 - mae: 45322.4258 - val_loss: 4605537280.0000 - val_mae: 47210.8555\n",
      "Epoch 49/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4131760640.0000 - mae: 45310.0117 - val_loss: 4631494656.0000 - val_mae: 47134.7070\n",
      "Epoch 50/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4123818240.0000 - mae: 45183.8945 - val_loss: 4589075968.0000 - val_mae: 47204.0703\n",
      "Epoch 51/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4121210112.0000 - mae: 45280.0195 - val_loss: 4588025856.0000 - val_mae: 46955.0977\n",
      "Epoch 52/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4116929280.0000 - mae: 45174.7383 - val_loss: 4574826496.0000 - val_mae: 47056.4805\n",
      "Epoch 53/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4110681600.0000 - mae: 45245.9062 - val_loss: 4596319744.0000 - val_mae: 46925.8633\n",
      "Epoch 54/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4104342016.0000 - mae: 45119.0430 - val_loss: 4589924864.0000 - val_mae: 47317.4648\n",
      "Epoch 55/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4108061696.0000 - mae: 45146.1289 - val_loss: 4567094272.0000 - val_mae: 46800.0352\n",
      "Epoch 56/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4099949824.0000 - mae: 45100.1797 - val_loss: 4561722368.0000 - val_mae: 46913.8320\n",
      "Epoch 57/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4093966848.0000 - mae: 45083.3477 - val_loss: 4556491776.0000 - val_mae: 46828.2500\n",
      "Epoch 58/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4090435072.0000 - mae: 45027.3984 - val_loss: 4570698240.0000 - val_mae: 46871.2109\n",
      "Epoch 59/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4090114048.0000 - mae: 44947.3398 - val_loss: 4559706112.0000 - val_mae: 46958.6562\n",
      "Epoch 60/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4085315328.0000 - mae: 44921.7266 - val_loss: 4575984128.0000 - val_mae: 47296.3750\n",
      "Epoch 61/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4084470528.0000 - mae: 44966.9258 - val_loss: 4550710784.0000 - val_mae: 46757.6172\n",
      "Epoch 62/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4076364288.0000 - mae: 44901.7148 - val_loss: 4561154048.0000 - val_mae: 46735.0391\n",
      "Epoch 63/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4067291136.0000 - mae: 44899.1211 - val_loss: 4581368832.0000 - val_mae: 46696.4688\n",
      "Epoch 64/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4077810688.0000 - mae: 44792.9609 - val_loss: 4542180352.0000 - val_mae: 46807.4336\n",
      "Epoch 65/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4072137984.0000 - mae: 44836.7969 - val_loss: 4546951680.0000 - val_mae: 46547.6758\n",
      "Epoch 66/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4064838400.0000 - mae: 44835.6641 - val_loss: 4549824512.0000 - val_mae: 46769.3477\n",
      "Epoch 67/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4061352448.0000 - mae: 44804.4258 - val_loss: 4543840768.0000 - val_mae: 46309.1211\n",
      "Epoch 68/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4059244800.0000 - mae: 44787.7617 - val_loss: 4542662656.0000 - val_mae: 46509.6445\n",
      "Epoch 69/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4057411328.0000 - mae: 44706.5391 - val_loss: 4540375040.0000 - val_mae: 46451.1680\n",
      "Epoch 70/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4052608768.0000 - mae: 44746.4180 - val_loss: 4546591744.0000 - val_mae: 46202.7227\n",
      "Epoch 71/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4049815552.0000 - mae: 44674.5117 - val_loss: 4529818112.0000 - val_mae: 46481.5586\n",
      "Epoch 72/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4050593536.0000 - mae: 44621.1719 - val_loss: 4534576128.0000 - val_mae: 46481.7539\n",
      "Epoch 73/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4051620864.0000 - mae: 44651.3633 - val_loss: 4529758208.0000 - val_mae: 46271.9688\n",
      "Epoch 74/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4045061376.0000 - mae: 44546.4570 - val_loss: 4543327744.0000 - val_mae: 46672.6875\n",
      "Epoch 75/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4041317376.0000 - mae: 44651.9297 - val_loss: 4544669184.0000 - val_mae: 46347.2070\n",
      "Epoch 76/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4046099200.0000 - mae: 44555.7031 - val_loss: 4514899456.0000 - val_mae: 46393.6250\n",
      "Epoch 77/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4034056960.0000 - mae: 44620.7383 - val_loss: 4538665472.0000 - val_mae: 46345.0156\n",
      "Epoch 78/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4034240768.0000 - mae: 44536.8906 - val_loss: 4508379648.0000 - val_mae: 46407.4219\n",
      "Epoch 79/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4026350848.0000 - mae: 44534.2578 - val_loss: 4507070464.0000 - val_mae: 46400.1445\n",
      "Epoch 80/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4032925440.0000 - mae: 44505.2500 - val_loss: 4504423936.0000 - val_mae: 46171.3242\n",
      "Epoch 81/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4026070784.0000 - mae: 44445.5742 - val_loss: 4482670592.0000 - val_mae: 46419.2500\n",
      "Epoch 82/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4021868544.0000 - mae: 44533.1875 - val_loss: 4491957760.0000 - val_mae: 46275.8555\n",
      "Epoch 83/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4018849024.0000 - mae: 44456.8906 - val_loss: 4493628928.0000 - val_mae: 46297.6797\n",
      "Epoch 84/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4015062016.0000 - mae: 44436.5859 - val_loss: 4495865856.0000 - val_mae: 46346.9531\n",
      "Epoch 85/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4010926080.0000 - mae: 44468.5078 - val_loss: 4511323136.0000 - val_mae: 45863.8164\n",
      "Epoch 86/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4013819904.0000 - mae: 44313.3906 - val_loss: 4481637888.0000 - val_mae: 46124.7734\n",
      "Epoch 87/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4007361792.0000 - mae: 44369.9883 - val_loss: 4477561856.0000 - val_mae: 46063.3750\n",
      "Epoch 88/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4007136512.0000 - mae: 44346.1133 - val_loss: 4479644672.0000 - val_mae: 46435.7695\n",
      "Epoch 89/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3997441280.0000 - mae: 44369.6875 - val_loss: 4503912448.0000 - val_mae: 46164.8555\n",
      "Epoch 90/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3998111232.0000 - mae: 44276.6602 - val_loss: 4482168832.0000 - val_mae: 45866.5391\n",
      "Epoch 91/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3996902400.0000 - mae: 44280.0859 - val_loss: 4473118720.0000 - val_mae: 46269.0469\n",
      "Epoch 92/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3994555648.0000 - mae: 44345.5977 - val_loss: 4473647104.0000 - val_mae: 46080.8008\n",
      "Epoch 93/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3994149888.0000 - mae: 44244.3750 - val_loss: 4458885632.0000 - val_mae: 45878.3828\n",
      "Epoch 94/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3986761728.0000 - mae: 44250.0117 - val_loss: 4450729472.0000 - val_mae: 46093.9141\n",
      "Epoch 95/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3984025344.0000 - mae: 44215.0430 - val_loss: 4461277184.0000 - val_mae: 45719.1992\n",
      "Epoch 96/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3985691392.0000 - mae: 44131.1328 - val_loss: 4475919360.0000 - val_mae: 45847.3125\n",
      "Epoch 97/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3979983360.0000 - mae: 44091.8633 - val_loss: 4461395968.0000 - val_mae: 46131.9883\n",
      "Epoch 98/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3979902720.0000 - mae: 44197.5781 - val_loss: 4439503360.0000 - val_mae: 45776.7188\n",
      "Epoch 99/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3975644160.0000 - mae: 44095.1797 - val_loss: 4425259520.0000 - val_mae: 45961.9180\n",
      "Epoch 100/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3964282880.0000 - mae: 44134.5508 - val_loss: 4472950784.0000 - val_mae: 45820.7773\n",
      "[192756.890625, 114392.390625, 66030.2578125, 57017.23828125, 53521.6796875, 51604.953125, 51043.91796875, 50408.32421875, 50231.0703125, 49552.87109375, 49672.08203125, 49800.66796875, 49689.06640625, 49207.796875, 48835.0859375, 48804.41796875, 49235.703125, 48636.33984375, 48742.3828125, 48871.70703125, 48243.83984375, 48307.01953125, 48506.65625, 48625.72265625, 48371.66796875, 48389.75390625, 48250.4296875, 48114.13671875, 48309.47265625, 47828.87890625, 48001.6953125, 48122.65234375, 47980.03125, 47980.37109375, 48490.51953125, 47469.61328125, 47405.109375, 47679.53125, 47249.0390625, 47308.27734375, 47292.1484375, 47198.71484375, 47323.95703125, 47459.83984375, 47142.76171875, 47283.453125, 46894.67578125, 47210.85546875, 47134.70703125, 47204.0703125, 46955.09765625, 47056.48046875, 46925.86328125, 47317.46484375, 46800.03515625, 46913.83203125, 46828.25, 46871.2109375, 46958.65625, 47296.375, 46757.6171875, 46735.0390625, 46696.46875, 46807.43359375, 46547.67578125, 46769.34765625, 46309.12109375, 46509.64453125, 46451.16796875, 46202.72265625, 46481.55859375, 46481.75390625, 46271.96875, 46672.6875, 46347.20703125, 46393.625, 46345.015625, 46407.421875, 46400.14453125, 46171.32421875, 46419.25, 46275.85546875, 46297.6796875, 46346.953125, 45863.81640625, 46124.7734375, 46063.375, 46435.76953125, 46164.85546875, 45866.5390625, 46269.046875, 46080.80078125, 45878.3828125, 46093.9140625, 45719.19921875, 45847.3125, 46131.98828125, 45776.71875, 45961.91796875, 45820.77734375]\n",
      "MAE for all folds:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 16\n",
    "all_mae_history = []\n",
    "    \n",
    "# get the compiled model\n",
    "model = get_model()\n",
    "\n",
    "history = model.fit(train_data, train_labels, epochs=num_epochs, batch_size=batch_size, validation_split=0.5, callbacks=[tensorboard], verbose=1)\n",
    "\n",
    "print(history.history[\"val_mae\"])\n",
    "\n",
    "print(f\"MAE for all folds:\\n{all_mae_history}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the best hyperparameters train the final model and evaluate on test data\n",
    "# model = get_model()\n",
    "# model.fit(train_data, train_labels, epochs=10, batch_size=16, verbose=0)\n",
    "# test_mse, test_mae = model.evaluate(test_data, test_labels)\n",
    "\n",
    "# print(test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[474559.22]\n",
      "500001.0\n"
     ]
    }
   ],
   "source": [
    "# generate the predictions on test data\n",
    "predictions = model.predict(test_data)\n",
    "print(predictions[0])\n",
    "print(test_labels[0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcacb1169d0317e97b762e0c1a317633c556cb59cb1017287d7e24b96b766e04"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('csi4106')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
