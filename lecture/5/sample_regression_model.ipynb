{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 25568), started 0:10:43 ago. (Use '!kill 25568' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-74d1db615a9c1584\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-74d1db615a9c1584\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                41.0        880.0           129.0   \n",
      "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2    -122.24     37.85                52.0       1467.0           190.0   \n",
      "3    -122.25     37.85                52.0       1274.0           235.0   \n",
      "4    -122.25     37.85                52.0       1627.0           280.0   \n",
      "\n",
      "   population  households  median_income  median_house_value ocean_proximity  \n",
      "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
      "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
      "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
      "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
      "4       565.0       259.0         3.8462            342200.0        NEAR BAY  \n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "df = pd.read_csv('./data/housing.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"income_cat\"] = pd.cut(df[\"median_income\"], bins=[0., 1.5, 3.0, 4.5, 6., np.inf], labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "# stratified(i.e., preserving the percentage of samples under each class) shuffle splitting the dataset\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(df, df[\"income_cat\"]):\n",
    "    strat_train_set = df.loc[train_index]\n",
    "    strat_test_set = df.loc[test_index]\n",
    "\n",
    "# drop the categorical feature as we do not need it anymore\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)\n",
    "\n",
    "data = strat_train_set.drop(\"median_house_value\", axis=1) \n",
    "train_labels = strat_train_set[\"median_house_value\"].to_numpy(copy=True)\n",
    "\n",
    "# creating a pipeline so that you can chain together multiple steps\n",
    "# NOTE: remember that the output from one step will be an inout to the other\n",
    "# you can do these steps seperately and combine but Pipelines are more efficient\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "housing_num = data.drop(\"ocean_proximity\", axis=1)\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "# will be applying tranasformer object to the given subset of data\n",
    "# NOTE: e.g., the \"num_pipeline\" transformer object will be applied on the given set of columns\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ])\n",
    "\n",
    " # sending the data through a chain of transformations\n",
    " # NOTE: the final dataset is a 2D numpy array containg all numerical data\n",
    "train_data = full_pipeline.fit_transform(data)\n",
    "\n",
    "# test the model on test data\n",
    "x_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "test_labels = strat_test_set[\"median_house_value\"].to_numpy(copy=True)\n",
    "\n",
    "test_data = full_pipeline.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "def get_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(256, input_shape=(13,), activation=\"relu\"),\n",
    "        layers.Dense(256, activation=\"relu\"),\n",
    "        layers.Dense(1)  # default linear activation due to the regression task\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard\n",
    "# create directory to store the callback logs\n",
    "d = datetime.datetime.today()\n",
    "timestamp = d.strftime('%Y%m%d_%H%M%S')\n",
    "tensorlog_folder = os.path.join(os.path.curdir, 'logs', timestamp)\n",
    "os.mkdir(tensorlog_folder)\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir=tensorlog_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "516/516 [==============================] - 3s 4ms/step - loss: 53445722112.0000 - mae: 201033.2656 - val_loss: 50290081792.0000 - val_mae: 192963.8594\n",
      "Epoch 2/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 36614770688.0000 - mae: 156571.2500 - val_loss: 22517041152.0000 - val_mae: 114052.8594\n",
      "Epoch 3/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 12268683264.0000 - mae: 79929.6641 - val_loss: 8387107840.0000 - val_mae: 65689.9766\n",
      "Epoch 4/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 6798501376.0000 - mae: 59174.9883 - val_loss: 6613744640.0000 - val_mae: 56887.0117\n",
      "Epoch 5/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 5644771328.0000 - mae: 53538.0273 - val_loss: 5772698112.0000 - val_mae: 53416.8750\n",
      "Epoch 6/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 5080924672.0000 - mae: 51105.1836 - val_loss: 5315293696.0000 - val_mae: 51854.6289\n",
      "Epoch 7/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4802476032.0000 - mae: 49958.5977 - val_loss: 5091350016.0000 - val_mae: 51023.4453\n",
      "Epoch 8/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4660296704.0000 - mae: 49210.2266 - val_loss: 4985563648.0000 - val_mae: 50421.0156\n",
      "Epoch 9/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4585229312.0000 - mae: 48784.1406 - val_loss: 4926572032.0000 - val_mae: 50320.6172\n",
      "Epoch 10/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4536724480.0000 - mae: 48536.7969 - val_loss: 4877899264.0000 - val_mae: 49807.1367\n",
      "Epoch 11/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4501154816.0000 - mae: 48259.7305 - val_loss: 4873799680.0000 - val_mae: 49874.8320\n",
      "Epoch 12/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4471435776.0000 - mae: 48131.9336 - val_loss: 4848282624.0000 - val_mae: 49261.8789\n",
      "Epoch 13/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4448026624.0000 - mae: 47954.1133 - val_loss: 4865084928.0000 - val_mae: 49111.4102\n",
      "Epoch 14/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4430875648.0000 - mae: 47677.3984 - val_loss: 4838283776.0000 - val_mae: 49728.0000\n",
      "Epoch 15/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4412224512.0000 - mae: 47702.5898 - val_loss: 4800809984.0000 - val_mae: 49132.2070\n",
      "Epoch 16/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4393180672.0000 - mae: 47511.5586 - val_loss: 4796920832.0000 - val_mae: 49143.6094\n",
      "Epoch 17/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4376024064.0000 - mae: 47416.9609 - val_loss: 4784021504.0000 - val_mae: 48902.9688\n",
      "Epoch 18/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4365787648.0000 - mae: 47293.4297 - val_loss: 4772328960.0000 - val_mae: 48626.3594\n",
      "Epoch 19/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4349587456.0000 - mae: 47165.0117 - val_loss: 4752681984.0000 - val_mae: 48668.7305\n",
      "Epoch 20/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4338641408.0000 - mae: 47040.5234 - val_loss: 4768539136.0000 - val_mae: 48756.5078\n",
      "Epoch 21/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4319909376.0000 - mae: 47002.4727 - val_loss: 4747176448.0000 - val_mae: 48938.2617\n",
      "Epoch 22/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4312245760.0000 - mae: 46937.0938 - val_loss: 4737187328.0000 - val_mae: 48383.8086\n",
      "Epoch 23/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4302773760.0000 - mae: 46745.5352 - val_loss: 4747130880.0000 - val_mae: 48577.7930\n",
      "Epoch 24/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4292564224.0000 - mae: 46691.0586 - val_loss: 4719131648.0000 - val_mae: 48574.7109\n",
      "Epoch 25/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4281610752.0000 - mae: 46710.5703 - val_loss: 4734644736.0000 - val_mae: 48311.9023\n",
      "Epoch 26/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4273029120.0000 - mae: 46569.3359 - val_loss: 4731766784.0000 - val_mae: 48629.9727\n",
      "Epoch 27/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4263074048.0000 - mae: 46414.1406 - val_loss: 4710602240.0000 - val_mae: 48427.0625\n",
      "Epoch 28/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4260235520.0000 - mae: 46368.3281 - val_loss: 4710412288.0000 - val_mae: 48553.7930\n",
      "Epoch 29/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4248256512.0000 - mae: 46354.3320 - val_loss: 4702216192.0000 - val_mae: 47952.0508\n",
      "Epoch 30/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4236845312.0000 - mae: 46236.6797 - val_loss: 4716914176.0000 - val_mae: 47941.0586\n",
      "Epoch 31/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4231379456.0000 - mae: 46146.7617 - val_loss: 4679719936.0000 - val_mae: 48240.2461\n",
      "Epoch 32/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4223112960.0000 - mae: 46117.4062 - val_loss: 4664604160.0000 - val_mae: 48035.9141\n",
      "Epoch 33/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4219818240.0000 - mae: 46045.6797 - val_loss: 4671113728.0000 - val_mae: 47699.6289\n",
      "Epoch 34/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4204712448.0000 - mae: 46022.1797 - val_loss: 4690120192.0000 - val_mae: 47415.2227\n",
      "Epoch 35/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4202321152.0000 - mae: 45908.8633 - val_loss: 4673739264.0000 - val_mae: 47494.8125\n",
      "Epoch 36/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4196533248.0000 - mae: 45899.2617 - val_loss: 4680687104.0000 - val_mae: 47844.6523\n",
      "Epoch 37/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4189346560.0000 - mae: 45849.6055 - val_loss: 4681642496.0000 - val_mae: 47628.8906\n",
      "Epoch 38/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4184385024.0000 - mae: 45783.4648 - val_loss: 4665914880.0000 - val_mae: 47720.4258\n",
      "Epoch 39/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4177103616.0000 - mae: 45756.0625 - val_loss: 4658352128.0000 - val_mae: 47615.7930\n",
      "Epoch 40/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4173221888.0000 - mae: 45664.1992 - val_loss: 4649733120.0000 - val_mae: 47745.4219\n",
      "Epoch 41/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4165961472.0000 - mae: 45640.6680 - val_loss: 4639348224.0000 - val_mae: 47460.9297\n",
      "Epoch 42/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4164351232.0000 - mae: 45577.2812 - val_loss: 4636911616.0000 - val_mae: 47248.7227\n",
      "Epoch 43/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4155453696.0000 - mae: 45457.7773 - val_loss: 4658166784.0000 - val_mae: 47809.4766\n",
      "Epoch 44/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4150652672.0000 - mae: 45483.4453 - val_loss: 4639566848.0000 - val_mae: 47432.9570\n",
      "Epoch 45/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4148451840.0000 - mae: 45460.8867 - val_loss: 4623687680.0000 - val_mae: 47155.3867\n",
      "Epoch 46/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4140226816.0000 - mae: 45368.2617 - val_loss: 4629683200.0000 - val_mae: 47593.2383\n",
      "Epoch 47/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4137257984.0000 - mae: 45381.8750 - val_loss: 4612351488.0000 - val_mae: 47347.7734\n",
      "Epoch 48/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4128831232.0000 - mae: 45372.5625 - val_loss: 4620434432.0000 - val_mae: 47173.9805\n",
      "Epoch 49/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4127758592.0000 - mae: 45242.9961 - val_loss: 4600100864.0000 - val_mae: 47056.4141\n",
      "Epoch 50/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4122780416.0000 - mae: 45277.9336 - val_loss: 4589792768.0000 - val_mae: 46867.4883\n",
      "Epoch 51/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4115988480.0000 - mae: 45278.6602 - val_loss: 4585209856.0000 - val_mae: 47072.9922\n",
      "Epoch 52/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4112332032.0000 - mae: 45198.1445 - val_loss: 4602559488.0000 - val_mae: 46932.2578\n",
      "Epoch 53/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4108827904.0000 - mae: 45193.3633 - val_loss: 4613620736.0000 - val_mae: 46911.4062\n",
      "Epoch 54/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4104061184.0000 - mae: 45113.9844 - val_loss: 4619665408.0000 - val_mae: 46890.4453\n",
      "Epoch 55/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4104580608.0000 - mae: 45044.1914 - val_loss: 4568508416.0000 - val_mae: 46843.8359\n",
      "Epoch 56/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4090830848.0000 - mae: 45067.5781 - val_loss: 4600945664.0000 - val_mae: 46665.4258\n",
      "Epoch 57/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4085485056.0000 - mae: 44934.8398 - val_loss: 4573888512.0000 - val_mae: 47022.3164\n",
      "Epoch 58/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4086488064.0000 - mae: 45033.1562 - val_loss: 4580511744.0000 - val_mae: 46910.8242\n",
      "Epoch 59/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4087893248.0000 - mae: 44965.3047 - val_loss: 4555807232.0000 - val_mae: 46663.7617\n",
      "Epoch 60/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4083025408.0000 - mae: 44979.6445 - val_loss: 4550298624.0000 - val_mae: 46650.8438\n",
      "Epoch 61/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4077414144.0000 - mae: 44927.6719 - val_loss: 4543040512.0000 - val_mae: 46672.7930\n",
      "Epoch 62/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4074603008.0000 - mae: 44887.8438 - val_loss: 4551469056.0000 - val_mae: 46643.8086\n",
      "Epoch 63/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4068215040.0000 - mae: 44902.5938 - val_loss: 4580938752.0000 - val_mae: 46522.0234\n",
      "Epoch 64/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4069139968.0000 - mae: 44792.6992 - val_loss: 4533103104.0000 - val_mae: 46588.3633\n",
      "Epoch 65/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4063554816.0000 - mae: 44826.2422 - val_loss: 4523452416.0000 - val_mae: 46554.1914\n",
      "Epoch 66/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4060398848.0000 - mae: 44757.6328 - val_loss: 4537920512.0000 - val_mae: 46713.1836\n",
      "Epoch 67/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4060470272.0000 - mae: 44749.3164 - val_loss: 4530130432.0000 - val_mae: 46350.5469\n",
      "Epoch 68/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4054102016.0000 - mae: 44729.1016 - val_loss: 4526036480.0000 - val_mae: 46515.4180\n",
      "Epoch 69/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4050815488.0000 - mae: 44725.9336 - val_loss: 4517903360.0000 - val_mae: 46452.3242\n",
      "Epoch 70/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4045500160.0000 - mae: 44645.2500 - val_loss: 4509668864.0000 - val_mae: 46330.7695\n",
      "Epoch 71/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4039870976.0000 - mae: 44646.6719 - val_loss: 4527185920.0000 - val_mae: 46754.4414\n",
      "Epoch 72/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4041295616.0000 - mae: 44576.6562 - val_loss: 4504783872.0000 - val_mae: 46803.6406\n",
      "Epoch 73/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4031823872.0000 - mae: 44623.1172 - val_loss: 4502120960.0000 - val_mae: 46456.4219\n",
      "Epoch 74/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4027474944.0000 - mae: 44681.7266 - val_loss: 4527341056.0000 - val_mae: 46178.3320\n",
      "Epoch 75/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4032571392.0000 - mae: 44497.4414 - val_loss: 4511770624.0000 - val_mae: 46526.5312\n",
      "Epoch 76/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4025727488.0000 - mae: 44528.9961 - val_loss: 4501996032.0000 - val_mae: 46381.7812\n",
      "Epoch 77/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4022811904.0000 - mae: 44473.6758 - val_loss: 4513326080.0000 - val_mae: 46159.3320\n",
      "Epoch 78/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4023926784.0000 - mae: 44499.3320 - val_loss: 4494723072.0000 - val_mae: 46108.0234\n",
      "Epoch 79/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4019232768.0000 - mae: 44483.3242 - val_loss: 4495232512.0000 - val_mae: 46056.0117\n",
      "Epoch 80/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4010270976.0000 - mae: 44445.4883 - val_loss: 4501758464.0000 - val_mae: 46379.6641\n",
      "Epoch 81/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4012621312.0000 - mae: 44482.7383 - val_loss: 4492714496.0000 - val_mae: 45995.7422\n",
      "Epoch 82/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 4006392320.0000 - mae: 44317.4883 - val_loss: 4475649024.0000 - val_mae: 46367.7500\n",
      "Epoch 83/100\n",
      "516/516 [==============================] - 2s 4ms/step - loss: 4003285760.0000 - mae: 44462.0586 - val_loss: 4476892672.0000 - val_mae: 46013.2148\n",
      "Epoch 84/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3998726656.0000 - mae: 44340.9609 - val_loss: 4462901248.0000 - val_mae: 46017.9258\n",
      "Epoch 85/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3994775808.0000 - mae: 44338.4062 - val_loss: 4477670912.0000 - val_mae: 46257.3203\n",
      "Epoch 86/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3994158592.0000 - mae: 44317.2383 - val_loss: 4455245312.0000 - val_mae: 45871.1836\n",
      "Epoch 87/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3988165632.0000 - mae: 44279.0703 - val_loss: 4473704448.0000 - val_mae: 45995.9180\n",
      "Epoch 88/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3986891008.0000 - mae: 44269.2422 - val_loss: 4463041024.0000 - val_mae: 46131.3398\n",
      "Epoch 89/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3986158592.0000 - mae: 44231.8203 - val_loss: 4466658816.0000 - val_mae: 46041.4258\n",
      "Epoch 90/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3980107008.0000 - mae: 44225.1289 - val_loss: 4448180224.0000 - val_mae: 45789.7031\n",
      "Epoch 91/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3974120448.0000 - mae: 44206.1133 - val_loss: 4445154304.0000 - val_mae: 45786.8633\n",
      "Epoch 92/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3972963328.0000 - mae: 44150.8438 - val_loss: 4458596864.0000 - val_mae: 45674.3242\n",
      "Epoch 93/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3973315584.0000 - mae: 44028.3867 - val_loss: 4431952384.0000 - val_mae: 45740.1602\n",
      "Epoch 94/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3968083712.0000 - mae: 44086.3203 - val_loss: 4415671808.0000 - val_mae: 45905.2500\n",
      "Epoch 95/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3960408320.0000 - mae: 44106.6211 - val_loss: 4430592512.0000 - val_mae: 45922.8555\n",
      "Epoch 96/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3958279168.0000 - mae: 44030.5391 - val_loss: 4423371776.0000 - val_mae: 45694.9453\n",
      "Epoch 97/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3952907520.0000 - mae: 44062.6641 - val_loss: 4418563072.0000 - val_mae: 45823.2188\n",
      "Epoch 98/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3949824000.0000 - mae: 44008.8164 - val_loss: 4427630080.0000 - val_mae: 45768.7539\n",
      "Epoch 99/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3948261632.0000 - mae: 43944.2305 - val_loss: 4400205312.0000 - val_mae: 45801.5195\n",
      "Epoch 100/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 3944077056.0000 - mae: 43986.9922 - val_loss: 4418311168.0000 - val_mae: 45750.0586\n",
      "[192963.859375, 114052.859375, 65689.9765625, 56887.01171875, 53416.875, 51854.62890625, 51023.4453125, 50421.015625, 50320.6171875, 49807.13671875, 49874.83203125, 49261.87890625, 49111.41015625, 49728.0, 49132.20703125, 49143.609375, 48902.96875, 48626.359375, 48668.73046875, 48756.5078125, 48938.26171875, 48383.80859375, 48577.79296875, 48574.7109375, 48311.90234375, 48629.97265625, 48427.0625, 48553.79296875, 47952.05078125, 47941.05859375, 48240.24609375, 48035.9140625, 47699.62890625, 47415.22265625, 47494.8125, 47844.65234375, 47628.890625, 47720.42578125, 47615.79296875, 47745.421875, 47460.9296875, 47248.72265625, 47809.4765625, 47432.95703125, 47155.38671875, 47593.23828125, 47347.7734375, 47173.98046875, 47056.4140625, 46867.48828125, 47072.9921875, 46932.2578125, 46911.40625, 46890.4453125, 46843.8359375, 46665.42578125, 47022.31640625, 46910.82421875, 46663.76171875, 46650.84375, 46672.79296875, 46643.80859375, 46522.0234375, 46588.36328125, 46554.19140625, 46713.18359375, 46350.546875, 46515.41796875, 46452.32421875, 46330.76953125, 46754.44140625, 46803.640625, 46456.421875, 46178.33203125, 46526.53125, 46381.78125, 46159.33203125, 46108.0234375, 46056.01171875, 46379.6640625, 45995.7421875, 46367.75, 46013.21484375, 46017.92578125, 46257.3203125, 45871.18359375, 45995.91796875, 46131.33984375, 46041.42578125, 45789.703125, 45786.86328125, 45674.32421875, 45740.16015625, 45905.25, 45922.85546875, 45694.9453125, 45823.21875, 45768.75390625, 45801.51953125, 45750.05859375]\n",
      "MAE for all folds:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 16\n",
    "all_mae_history = []\n",
    "    \n",
    "# get the compiled model\n",
    "model = get_model()\n",
    "\n",
    "history = model.fit(train_data, train_labels, epochs=num_epochs, batch_size=batch_size, validation_split=0.5, callbacks=[tensorboard], verbose=1)\n",
    "\n",
    "print(history.history[\"val_mae\"])\n",
    "\n",
    "print(f\"MAE for all folds:\\n{all_mae_history}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 0s 1ms/step - loss: 4414666752.0000 - mae: 48674.4023\n",
      "48674.40234375\n"
     ]
    }
   ],
   "source": [
    "# based on the best hyperparameters train the final model and evaluate on test data\n",
    "model = get_model()\n",
    "model.fit(train_data, train_labels, epochs=10, batch_size=16, verbose=0)\n",
    "test_mse, test_mae = model.evaluate(test_data, test_labels)\n",
    "\n",
    "print(test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[443780.62]\n",
      "500001.0\n"
     ]
    }
   ],
   "source": [
    "# generate the predictions on test data\n",
    "predictions = model.predict(test_data)\n",
    "print(predictions[0])\n",
    "print(test_labels[0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcacb1169d0317e97b762e0c1a317633c556cb59cb1017287d7e24b96b766e04"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('csi4106')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
