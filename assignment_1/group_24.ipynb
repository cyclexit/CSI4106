{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "## Group 24\n",
    "|Name|Student No.|Email\n",
    "|----|-----------|-----\n",
    "|Hongyi Lin| 300053082| hlin087@uottawa.ca\n",
    "|Rodger Retanal| 300052309| rreta014@uottawa.ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "import matplotlib.pyplot as plot\n",
    "# we can use the LabelEncoder to encode the gender feature\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# importing two different imputation methods that take into consideration all the features when predicting the missing values\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# oversample the minority class using SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "np.random.seed(42)\n",
    "JOB_NUM = multiprocessing.cpu_count() // 2 - 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data loading and exploratory analysis (18/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe shape: (615, 14)\n",
      "\n",
      "dataframe columns: Index(['Age', 'Sex', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA',\n",
      "       'GGT', 'PROT', 'split', 'category'],\n",
      "      dtype='object')\n",
      "\n",
      "All data types of dataframe:\n",
      " Age           int64\n",
      "Sex          object\n",
      "ALB         float64\n",
      "ALP         float64\n",
      "ALT         float64\n",
      "AST         float64\n",
      "BIL         float64\n",
      "CHE         float64\n",
      "CHOL        float64\n",
      "CREA        float64\n",
      "GGT         float64\n",
      "PROT        float64\n",
      "split        object\n",
      "category      int64\n",
      "dtype: object\n",
      "\n",
      "Gender distribution:\n",
      " m    377\n",
      "f    238\n",
      "Name: Sex, dtype: int64\n",
      "\n",
      "Class distribution of the entire dataset:\n",
      " 0    540\n",
      "1     75\n",
      "Name: category, dtype: int64\n",
      "\n",
      "Median age of the patients with hepatitis C infection: 49.0\n",
      "\n",
      "Mean age of the patients without hepatitis C infection: 47.266666666666666\n",
      "\n",
      "test_set shape: (185, 14)\n",
      "\n",
      "train_set shape: (430, 14)\n",
      "\n",
      "Class distribution in test_set:\n",
      " 0    163\n",
      "1     22\n",
      "Name: category, dtype: int64\n",
      "\n",
      "Class distribution in train_set:\n",
      " 0    377\n",
      "1     53\n",
      "Name: category, dtype: int64\n",
      "\n",
      "We think the feature \"CHOL\" has a rough approximation of a Gaussian distribution\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"ALB\" and \"PROT\" has a notable correlation with value 0.557196911828285\n",
      "\"AST\" and \"category\" has a notable correlation with value 0.6217239773457609\n"
     ]
    }
   ],
   "source": [
    "# load the dataset (1)\n",
    "dataframe = pd.read_csv('./hcv_data_split.csv')\n",
    "\n",
    "# print the dimensionality of the dataframe (1)\n",
    "print(f\"dataframe shape: {dataframe.shape}\\n\")\n",
    "\n",
    "# print the names of the columns that can be used as features when training the machine learning model (1)\n",
    "print(f\"dataframe columns: {dataframe.columns}\\n\")\n",
    "\n",
    "# print the different data types that can be identified from the entire dataset (1)\n",
    "print(f\"All data types of dataframe:\\n {dataframe.dtypes}\\n\")\n",
    "\n",
    "# print the gender distribution in the complete dataset(i.e., the number of male and female individuals) (1)\n",
    "print(f\"Gender distribution:\\n {dataframe['Sex'].value_counts()}\\n\")\n",
    "\n",
    "# print the class distribution of the entire dataset (1)\n",
    "print(f\"Class distribution of the entire dataset:\\n {dataframe['category'].value_counts()}\\n\")\n",
    "\n",
    "# print the median age of patients in the dataset having the hepatitis C infection (1.5)\n",
    "patients_with_hepatitis_c = dataframe.loc[dataframe['category'] == 1]\n",
    "print(f\"Median age of the patients with hepatitis C infection: {patients_with_hepatitis_c['Age'].median()}\\n\")\n",
    "# print(dataframe['category'].value_counts(), patients_with_hepatitis_c.shape) # TEST\n",
    "\n",
    "# print the mean age of individuals in the dataset who does not have hepatitis C infection(i.e., the control group) (1.5)\n",
    "patients_without_hepatitis_c = dataframe.loc[dataframe['category'] == 0]\n",
    "print(f\"Mean age of the patients without hepatitis C infection: {patients_without_hepatitis_c['Age'].mean()}\\n\")\n",
    "# print(dataframe['category'].value_counts(), patients_without_hepatitis_c.shape) # TEST\n",
    "\n",
    "# split the dataset into train and test based on the field \"split\" (0.5 + 0.5)\n",
    "test_set = dataframe.loc[dataframe['split'] == 'test']\n",
    "train_set = dataframe.loc[dataframe['split'] == 'train']\n",
    "\n",
    "# print the dimensionality of the test dataset (0.5)\n",
    "print(f\"test_set shape: {test_set.shape}\\n\")\n",
    "\n",
    "# print the dimensionality of the training dataset (0.5)\n",
    "print(f\"train_set shape: {train_set.shape}\\n\")\n",
    "\n",
    "# print the proportional distribution of the classes to identify whether or not the classes are equally(or closer) distributed between the train and test datasets (1 + 1)\n",
    "print(f\"Class distribution in test_set:\\n {test_set['category'].value_counts()}\\n\")\n",
    "print(f\"Class distribution in train_set:\\n {train_set['category'].value_counts()}\\n\")\n",
    "\n",
    "# analyze the distribution of the individual features(i.e., by using the complete dataset) and plot a feature that has a rough approximation of a Gaussian distribution (2)\n",
    "# for col in dataframe:\n",
    "#     dataframe[col].hist(bins=20)\n",
    "#     print(col)\n",
    "#     plot.show()\n",
    "print(\"We think the feature \\\"CHOL\\\" has a rough approximation of a Gaussian distribution\")\n",
    "dataframe[\"CHOL\"].hist(bins=20)\n",
    "plot.show()\n",
    "\n",
    "# EXTRA: normality test\n",
    "# from scipy.stats import shapiro, normaltest\n",
    "# ALPHA = 0.05\n",
    "# for col in dataframe:\n",
    "#     print(dataframe[col].values.dtype)\n",
    "#     if (dataframe[col].values.dtype == np.float64) or (dataframe[col].values.dtype == np.int64):\n",
    "#         stat, p = normaltest(dataframe[col].dropna(inplace=False).values)\n",
    "#         print(f\"{col}, stat={stat}, p={p}\")\n",
    "#         if p > ALPHA:\n",
    "#             print(f\"{col} looks like Gaussian distribution\")\n",
    "# print()\n",
    "\n",
    "# identify features that represent a notable correlation (i.e., either positive or negative correlation below or above -0.5 and 0.5) (3)\n",
    "corr_matrix = dataframe.corr()\n",
    "cols = list(corr_matrix.columns)\n",
    "for i in range(0, len(cols)):\n",
    "    for j in range(i + 1, len(cols)):\n",
    "        if abs(corr_matrix.values[i, j]) > 0.5:\n",
    "            print(f\"\\\"{cols[i]}\\\" and \\\"{cols[j]}\\\" has a notable correlation with value {corr_matrix.values[i, j]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model development (64/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape: (430, 13)\n",
      "labels shape: (430,)\n",
      "\n",
      "5 rows are incomplete\n",
      "\n",
      "Before the data imputation:\n",
      "data shape: (430, 11)\n",
      "    Age   ALB   ALP    ALT    AST   BIL    CHE  CHOL  CREA   GGT  PROT\n",
      "4    59  36.0   NaN  100.0   80.0  12.0   9.07   5.3  67.0  34.0  68.0\n",
      "6    32  47.4  52.5   19.1   17.1   4.6  10.19   NaN  63.0  23.0  72.2\n",
      "8    50  42.0   NaN  258.0  106.0  15.0   8.74   4.7  77.0  80.0  84.0\n",
      "42   46  42.9  55.1   15.2   29.8   3.6   8.37   NaN  61.0  29.0  71.9\n",
      "59   49  39.0   NaN  118.0   62.0  10.0   7.28   3.5  72.0  74.0  81.0 \n",
      "\n",
      "After the data imputation:\n",
      "data shape: (430, 11)\n",
      "     Age   ALB    ALP    ALT    AST   BIL    CHE   CHOL  CREA   GGT  PROT\n",
      "4   59.0  36.0  63.76  100.0   80.0  12.0   9.07  5.300  67.0  34.0  68.0\n",
      "6   32.0  47.4  52.50   19.1   17.1   4.6  10.19  4.910  63.0  23.0  72.2\n",
      "8   50.0  42.0  70.86  258.0  106.0  15.0   8.74  4.700  77.0  80.0  84.0\n",
      "42  46.0  42.9  55.10   15.2   29.8   3.6   8.37  6.054  61.0  29.0  71.9\n",
      "59  49.0  39.0  67.66  118.0   62.0  10.0   7.28  3.500  72.0  74.0  81.0\n"
     ]
    }
   ],
   "source": [
    "# separate the features and the labels to be used in model development (2)\n",
    "train_data = train_set.drop(\"category\", axis=1)\n",
    "labels = train_set[\"category\"].copy()\n",
    "\n",
    "# print the dimensionality of the dataset and the labels (0.5 + 0.5)\n",
    "print(f\"train_data shape: {train_data.shape}\")\n",
    "print(f\"labels shape: {labels.shape}\\n\")\n",
    "\n",
    "# check for missing values in the training dataset and print how many rows can be identified with the missing values (1)\n",
    "incomplete_rows_in_train_data = train_data[train_data.isnull().any(axis=1)].head()\n",
    "print(f\"{incomplete_rows_in_train_data.shape[0]} rows are incomplete\\n\")\n",
    "\n",
    "# data imputation\n",
    "# given the task in predicting individuals with hepatitis C infection, select two of the most appropriate imputation strategies to fill the missing values and briefly explain why you have selected the particular strategies in a markdown cell below the current cell (3)\n",
    "imputer_simple = SimpleImputer(strategy='median')\n",
    "imputer_knn = KNNImputer(n_neighbors=5)\n",
    "imputer_iter = IterativeImputer(max_iter=10)\n",
    "\n",
    "# print the rows before and after being imputed with the two selected strategies (5)\n",
    "train_data_to_impute = train_data.drop([\"Sex\", \"split\"], axis=1)\n",
    "print(\"Before the data imputation:\")\n",
    "print(f\"data shape: {train_data_to_impute.shape}\")\n",
    "print(train_data_to_impute.loc[incomplete_rows_in_train_data.index.values], '\\n')\n",
    "\n",
    "imputer_knn.fit(train_data_to_impute)\n",
    "temp = imputer_knn.transform(train_data_to_impute)\n",
    "train_data_imputed = pd.DataFrame(\n",
    "    temp,\n",
    "    columns=train_data_to_impute.columns,\n",
    "    index=train_data_to_impute.index\n",
    ")\n",
    "\n",
    "print(\"After the data imputation:\")\n",
    "print(f\"data shape: {train_data_imputed.shape}\")\n",
    "print(train_data_imputed.loc[incomplete_rows_in_train_data.index.values])\n",
    "\n",
    "# indicate the encoding strategy that is more appropriate given the categorical feature 'Sex' and briefly explain why you selected one strategy over the other (i.e., either OrdinalEncoder or OneHotEncoder) in the markdown cell mentioned below (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data imputations explanation?\n",
    "\n",
    "**Answer**: KNNImputer and IterativeImputer are chosen. Median-value imputation just simple uses the median value to fill the null data. This will cause the distortion of the original variable distribution and the original variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical data encoding strategy explanation?\n",
    "\n",
    "**Answer**: OneHotEncoder is chosen. In the dataset of this assignment, the data is not in an ordinal order and does not have a natural rank. Hence, using the OrdinalEncoder will not be appropriate and may mislead the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(430, 14)\n",
      "[[0.68965517 0.29411765 0.16251572 ... 0.         1.         1.        ]\n",
      " [0.37931034 0.18600954 0.16654088 ... 0.         1.         1.        ]\n",
      " [0.98275862 0.15739269 0.07496855 ... 0.         1.         1.        ]\n",
      " ...\n",
      " [0.25862069 0.26868045 0.13031447 ... 1.         0.         1.        ]\n",
      " [0.36206897 0.31319555 0.06037736 ... 0.         1.         1.        ]\n",
      " [0.65517241 0.38473768 0.09333333 ... 0.         1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# select one of the scaling strategies and briefly explain why it is essential to scale your features in the markdown cell mentioned below (3)\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# create the necessary pipelines and combine the features to be used as the training data for the given algorithm (8)\n",
    "num_attrs = list(train_data_to_impute)\n",
    "cat_attrs = ['Sex', 'split'] # NOTE: Do we need to encode the \"split\" columns?\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', imputer_knn),\n",
    "    ('std_scaler', min_max_scaler)\n",
    "])\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attrs),\n",
    "    (\"cat\", OneHotEncoder(), cat_attrs)\n",
    "])\n",
    "train_data_prepared = full_pipeline.fit_transform(train_data)\n",
    "print(train_data_prepared.shape)\n",
    "print(train_data_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why scaling?\n",
    "\n",
    "**Answer**: We chose the MinMaxScaler here. Scaling the data can make the values of the features closer to each other so that the algorithm can train a model better and faster. If the features' values have huge differences with each other, it will take more time for the algorithm to understand the data and the accuracy will also be lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the following four different models with their default hyperparameter values to be trained using the preprocessed data (0.5 * 4)\n",
    "# Support Vector Machine\n",
    "model_svc = SVC()\n",
    "# Decision Tree\n",
    "model_decision_tree = DecisionTreeClassifier()\n",
    "# Random Forests\n",
    "model_random_forests = RandomForestClassifier()\n",
    "# Naive Bayes\n",
    "model_naive_bayes = GaussianNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We choose the random forests algorithm\n",
      "\n",
      "Best parameters: {'bootstrap': False, 'min_samples_split': 5, 'n_estimators': 100, 'random_state': 42}\n",
      "Best estimator: RandomForestClassifier(bootstrap=False, min_samples_split=5, random_state=42)\n",
      "Best score: 0.9097496012759171\n"
     ]
    }
   ],
   "source": [
    "# use sklearn GridSearchCV to train your selected model with hyperparameter tuning\n",
    "# state briefly the advantage of using cross-validation in the markdown cell below (2)\n",
    "\n",
    "# finetune 2 or more of the hyperparameters mentioned below and use at least 2 different values for each hyperparameter except for the Naive Bayes algorithm(use param_grid={}) (8)\n",
    "# parameters for SVC:\n",
    "    # C -> e.g., 10, 100\n",
    "    # gamma ->  e.g., 0.001, 0.0001\n",
    "    # kernel -> 'rbf' or 'linear'\n",
    "params_svc = [\n",
    "    {\n",
    "        'kernel': ['rbf', 'sigmoid'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    }\n",
    "]\n",
    "\n",
    "# parameters for DecisionTreeClassifier: \n",
    "    # max_depth ->  e.g., 3, 4\n",
    "    # min_samples_split -> 5, 10\n",
    "    # min_samples_leaf -> 10, 20\n",
    "params_decision_tree = [\n",
    "    {\n",
    "        'min_samples_split': [5, 10],\n",
    "        'min_samples_leaf': [10, 20]\n",
    "    },\n",
    "]\n",
    "\n",
    "# parameters for RandomForestClassifier: \n",
    "    # n_estimators -> 100, 200\n",
    "    # max_depth -> 3, 5\n",
    "    # bootstrap -> True, False\n",
    "params_random_forests = [\n",
    "    {\n",
    "        'n_estimators': [100, 200, 250, 300],\n",
    "        'min_samples_split': [5, 10],\n",
    "        'random_state': [42, 50],\n",
    "        'bootstrap': [False, True]\n",
    "    }\n",
    "]\n",
    "\n",
    "params_naive_bayes = [{}] # empty for naive bayes\n",
    "\n",
    "# initialize gridsearch with the required parameters, including the following scoring methods and refit='bal_accuracy' (2)\n",
    "scoring = {\"accuracy\": \"accuracy\", \"bal_accuracy\": \"balanced_accuracy\", \"F1_macro\": \"f1_macro\"}\n",
    "\n",
    "print(\"We choose the random forests algorithm\\n\")\n",
    "\n",
    "grid_search_random_forests = GridSearchCV(\n",
    "    model_random_forests,\n",
    "    params_random_forests,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True,\n",
    "    refit='bal_accuracy',\n",
    "    n_jobs=JOB_NUM\n",
    ")\n",
    "\n",
    "# fit the training data (0.5)\n",
    "grid_search_random_forests.fit(train_data_prepared, labels)\n",
    "\n",
    "# print the best parameters (0.5)\n",
    "print(f\"Best parameters: {grid_search_random_forests.best_params_}\")\n",
    "\n",
    "# print the best estimator (0.5)\n",
    "print(f\"Best estimator: {grid_search_random_forests.best_estimator_}\")\n",
    "\n",
    "# print the best score from trained GridSearchCV model (0.5)\n",
    "print(f\"Best score: {grid_search_random_forests.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why should you use cross-validation?\n",
    "\n",
    "**Answer**: The cross-validation has the following advantages:\n",
    "* **Reduce overfitting**: In the cross-validation, we split the original dataset into several subsets and we use some subsets to train the model and the others to test the model. Hence, we can prevent our model from overfitting the training dataset and make our model more general.\n",
    "* **Hyperparameter Tuning**: Cross-validation can also help us tune the values of hyperparameters so that the optimal values can be found to improve the efficiency of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': False, 'min_samples_split': 5, 'n_estimators': 100, 'random_state': 42}\n",
      "mean_accuracy=0.9674418604651163, mean_bal_accuracy=0.9097496012759171, mean_F1_macro=0.9219758694349925\n",
      "\n",
      "{'bootstrap': False, 'min_samples_split': 5, 'n_estimators': 100, 'random_state': 50}\n",
      "mean_accuracy=0.9604651162790697, mean_bal_accuracy=0.8989011164274322, mean_F1_macro=0.9064803073545974\n",
      "\n",
      "{'bootstrap': False, 'min_samples_split': 5, 'n_estimators': 200, 'random_state': 42}\n",
      "mean_accuracy=0.9674418604651163, mean_bal_accuracy=0.9097496012759171, mean_F1_macro=0.9219758694349925\n",
      "\n",
      "{'bootstrap': False, 'min_samples_split': 5, 'n_estimators': 200, 'random_state': 50}\n",
      "mean_accuracy=0.9627906976744185, mean_bal_accuracy=0.8993253588516745, mean_F1_macro=0.9113029647167368\n",
      "\n",
      "{'bootstrap': False, 'min_samples_split': 5, 'n_estimators': 250, 'random_state': 42}\n",
      "mean_accuracy=0.9651162790697674, mean_bal_accuracy=0.9084162679425838, mean_F1_macro=0.91709454848556\n",
      "\n",
      "{'bootstrap': False, 'min_samples_split': 5, 'n_estimators': 250, 'random_state': 50}\n",
      "mean_accuracy=0.9604651162790697, mean_bal_accuracy=0.8979920255183412, mean_F1_macro=0.9070566144324526\n",
      "\n",
      "{'bootstrap': False, 'min_samples_split': 5, 'n_estimators': 300, 'random_state': 42}\n",
      "mean_accuracy=0.9674418604651163, mean_bal_accuracy=0.9097496012759171, mean_F1_macro=0.9219758694349925\n",
      "\n",
      "{'bootstrap': False, 'min_samples_split': 5, 'n_estimators': 300, 'random_state': 50}\n",
      "mean_accuracy=0.9604651162790697, mean_bal_accuracy=0.8979920255183412, mean_F1_macro=0.9070566144324526\n",
      "\n",
      "{'bootstrap': False, 'min_samples_split': 10, 'n_estimators': 100, 'random_state': 42}\n",
      "mean_accuracy=0.9604651162790697, mean_bal_accuracy=0.8979920255183412, mean_F1_macro=0.9057127133741634\n",
      "\n",
      "{'bootstrap': False, 'min_samples_split': 10, 'n_estimators': 100, 'random_state': 50}\n",
      "mean_accuracy=0.9627906976744185, mean_bal_accuracy=0.9070829346092504, mean_F1_macro=0.9127820801958523\n",
      "\n",
      "{'bootstrap': False, 'min_samples_split': 10, 'n_estimators': 200, 'random_state': 42}\n",
      "mean_accuracy=0.9627906976744185, mean_bal_accuracy=0.8993253588516745, mean_F1_macro=0.9100251816638714\n",
      "\n",
      "{'bootstrap': False, 'min_samples_split': 10, 'n_estimators': 200, 'random_state': 50}\n",
      "mean_accuracy=0.9627906976744185, mean_bal_accuracy=0.8993253588516745, mean_F1_macro=0.9100251816638714\n",
      "\n",
      "{'bootstrap': False, 'min_samples_split': 10, 'n_estimators': 250, 'random_state': 42}\n",
      "mean_accuracy=0.9627906976744185, mean_bal_accuracy=0.8993253588516745, mean_F1_macro=0.9100251816638714\n",
      "\n",
      "{'bootstrap': False, 'min_samples_split': 10, 'n_estimators': 250, 'random_state': 50}\n",
      "mean_accuracy=0.9604651162790697, mean_bal_accuracy=0.8979920255183412, mean_F1_macro=0.9057127133741634\n",
      "\n",
      "{'bootstrap': False, 'min_samples_split': 10, 'n_estimators': 300, 'random_state': 42}\n",
      "mean_accuracy=0.9627906976744185, mean_bal_accuracy=0.8993253588516745, mean_F1_macro=0.9100251816638714\n",
      "\n",
      "{'bootstrap': False, 'min_samples_split': 10, 'n_estimators': 300, 'random_state': 50}\n",
      "mean_accuracy=0.9604651162790697, mean_bal_accuracy=0.8979920255183412, mean_F1_macro=0.9057127133741634\n",
      "\n",
      "{'bootstrap': True, 'min_samples_split': 5, 'n_estimators': 100, 'random_state': 42}\n",
      "mean_accuracy=0.9581395348837211, mean_bal_accuracy=0.8889186602870813, mean_F1_macro=0.9004195976538032\n",
      "\n",
      "{'bootstrap': True, 'min_samples_split': 5, 'n_estimators': 100, 'random_state': 50}\n",
      "mean_accuracy=0.9604651162790697, mean_bal_accuracy=0.8902344497607656, mean_F1_macro=0.9050522563092223\n",
      "\n",
      "{'bootstrap': True, 'min_samples_split': 5, 'n_estimators': 200, 'random_state': 42}\n",
      "mean_accuracy=0.9651162790697674, mean_bal_accuracy=0.9006586921850079, mean_F1_macro=0.9154764987334646\n",
      "\n",
      "{'bootstrap': True, 'min_samples_split': 5, 'n_estimators': 200, 'random_state': 50}\n",
      "mean_accuracy=0.9651162790697674, mean_bal_accuracy=0.9093253588516748, mean_F1_macro=0.917029646308284\n",
      "\n",
      "{'bootstrap': True, 'min_samples_split': 5, 'n_estimators': 250, 'random_state': 42}\n",
      "mean_accuracy=0.9651162790697674, mean_bal_accuracy=0.9093429027113238, mean_F1_macro=0.9172783086022974\n",
      "\n",
      "{'bootstrap': True, 'min_samples_split': 5, 'n_estimators': 250, 'random_state': 50}\n",
      "mean_accuracy=0.9627906976744185, mean_bal_accuracy=0.9002344497607655, mean_F1_macro=0.9107573490690994\n",
      "\n",
      "{'bootstrap': True, 'min_samples_split': 5, 'n_estimators': 300, 'random_state': 42}\n",
      "mean_accuracy=0.9604651162790697, mean_bal_accuracy=0.8902344497607656, mean_F1_macro=0.9050522563092223\n",
      "\n",
      "{'bootstrap': True, 'min_samples_split': 5, 'n_estimators': 300, 'random_state': 50}\n",
      "mean_accuracy=0.9604651162790697, mean_bal_accuracy=0.8902344497607656, mean_F1_macro=0.9043228805448476\n",
      "\n",
      "{'bootstrap': True, 'min_samples_split': 10, 'n_estimators': 100, 'random_state': 42}\n",
      "mean_accuracy=0.9627906976744185, mean_bal_accuracy=0.8915502392344499, mean_F1_macro=0.9095012272156151\n",
      "\n",
      "{'bootstrap': True, 'min_samples_split': 10, 'n_estimators': 100, 'random_state': 50}\n",
      "mean_accuracy=0.9534883720930232, mean_bal_accuracy=0.870719298245614, mean_F1_macro=0.8852836222002306\n",
      "\n",
      "{'bootstrap': True, 'min_samples_split': 10, 'n_estimators': 200, 'random_state': 42}\n",
      "mean_accuracy=0.9581395348837211, mean_bal_accuracy=0.8811610845295057, mean_F1_macro=0.8959565269184864\n",
      "\n",
      "{'bootstrap': True, 'min_samples_split': 10, 'n_estimators': 200, 'random_state': 50}\n",
      "mean_accuracy=0.9558139534883721, mean_bal_accuracy=0.880719298245614, mean_F1_macro=0.8917180907244824\n",
      "\n",
      "{'bootstrap': True, 'min_samples_split': 10, 'n_estimators': 250, 'random_state': 42}\n",
      "mean_accuracy=0.9534883720930234, mean_bal_accuracy=0.8707368421052631, mean_F1_macro=0.8848029087298693\n",
      "\n",
      "{'bootstrap': True, 'min_samples_split': 10, 'n_estimators': 250, 'random_state': 50}\n",
      "mean_accuracy=0.9534883720930232, mean_bal_accuracy=0.870719298245614, mean_F1_macro=0.8852836222002306\n",
      "\n",
      "{'bootstrap': True, 'min_samples_split': 10, 'n_estimators': 300, 'random_state': 42}\n",
      "mean_accuracy=0.9558139534883721, mean_bal_accuracy=0.8807368421052632, mean_F1_macro=0.8912373772541212\n",
      "\n",
      "{'bootstrap': True, 'min_samples_split': 10, 'n_estimators': 300, 'random_state': 50}\n",
      "mean_accuracy=0.9558139534883721, mean_bal_accuracy=0.8720526315789474, mean_F1_macro=0.8894355673852884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the grid search cross-validation results listing the above mentioned evaluation methods (3)\n",
    "# NOTE: what is the difference between std_... and mean_...?\n",
    "cv_results = grid_search_random_forests.cv_results_\n",
    "# print(cv_results) # TEST\n",
    "for mean_accuracy, mean_bal_accuracy, mean_F1_macro, params in zip(cv_results['mean_test_accuracy'], cv_results['mean_test_bal_accuracy'], cv_results['mean_test_F1_macro'], cv_results['params']):\n",
    "    print(params)\n",
    "    print(f\"mean_accuracy={mean_accuracy}, mean_bal_accuracy={mean_bal_accuracy}, mean_F1_macro={mean_F1_macro}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(strategy='most_frequent')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a dummy classifier to identify a simple baseline (i.e., a majority class baseline) so that you can compare your prediction results (3)\n",
    "model_dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "model_dummy.fit(train_data_prepared, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data shape: (185, 13)\n",
      "test_labels shape: (185,)\n",
      "\n",
      "Classification Report (Test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       163\n",
      "           1       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.94       185\n",
      "   macro avg       0.97      0.75      0.82       185\n",
      "weighted avg       0.94      0.94      0.93       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prepare the test data to be predicted (2)\n",
    "test_data = test_set.drop(\"category\", axis=1)\n",
    "test_labels = test_set[\"category\"].copy()\n",
    "\n",
    "# print the dimensionality of the dataset and the labels (0.5 + 0.5)\n",
    "print(f\"test_data shape: {test_data.shape}\")\n",
    "print(f\"test_labels shape: {test_labels.shape}\\n\")\n",
    "\n",
    "# transform test data for prediction (2)\n",
    "test_data_prepared = full_pipeline.fit_transform(test_data)\n",
    "\n",
    "# obtain predictions on test data using the best model from GridSearchCV (i.e., .best_estimator_) (2)\n",
    "test_predictions = grid_search_random_forests.best_estimator_.predict(test_data_prepared)\n",
    "\n",
    "# generate the classification report and the confusion matrix for test predictions (3)\n",
    "classification_report_test = classification_report(test_labels, test_predictions)\n",
    "print(f\"Classification Report (Test):\\n {classification_report_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to print the data for the table\n",
    "def print_table_data(grid_search_list, train_data, train_labels, test_data, test_labels):\n",
    "    for gs in grid_search_list:\n",
    "        gs['grid_search'].fit(train_data, train_labels)\n",
    "        \n",
    "        print(gs['model_name'])\n",
    "        print(f\"best score: {gs['grid_search'].best_score_}\")\n",
    "        print(f\"best parameters: {gs['grid_search'].best_params_}\")\n",
    "        \n",
    "        # validation data\n",
    "        cv_results = gs['grid_search'].cv_results_\n",
    "        print(f\"best accuracy (validation): {max(cv_results['mean_test_accuracy'])}\")\n",
    "        print(f\"best f1_macro (validation): {max(cv_results['mean_test_F1_macro'])}\")\n",
    "        for mean_accuracy, mean_F1_macro, params in zip(cv_results['mean_test_accuracy'], cv_results['mean_test_F1_macro'], cv_results['params']):\n",
    "            if params == gs['grid_search'].best_params_:\n",
    "                # print(f\"mean_accuracy={mean_accuracy}, mean_F1_macro={mean_F1_macro}\\n\")\n",
    "                if mean_accuracy == max(cv_results['mean_test_accuracy']) \\\n",
    "                    and mean_F1_macro == max(cv_results['mean_test_F1_macro']):\n",
    "                    print(\"Verified\")\n",
    "        \n",
    "        # test data\n",
    "        test_predictions = gs['grid_search'].best_estimator_.predict(test_data)\n",
    "        classification_report_test = classification_report(test_labels, test_predictions)\n",
    "        print(f\"Classification Report (Test):\\n {classification_report_test}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine\n",
      "best score: 0.6678532695374801\n",
      "best parameters: {'gamma': 'scale', 'kernel': 'rbf'}\n",
      "best accuracy (validation): 0.9116279069767442\n",
      "best f1_macro (validation): 0.7153030807615023\n",
      "Verified\n",
      "Classification Report (Test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       163\n",
      "           1       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.93       185\n",
      "   macro avg       0.96      0.70      0.77       185\n",
      "weighted avg       0.93      0.93      0.92       185\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "best score: 0.8616283891547049\n",
      "best parameters: {'min_samples_leaf': 20, 'min_samples_split': 5}\n",
      "best accuracy (validation): 0.9511627906976743\n",
      "best f1_macro (validation): 0.8791111379160915\n",
      "Verified\n",
      "Classification Report (Test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97       163\n",
      "           1       0.92      0.55      0.69        22\n",
      "\n",
      "    accuracy                           0.94       185\n",
      "   macro avg       0.93      0.77      0.83       185\n",
      "weighted avg       0.94      0.94      0.93       185\n",
      "\n",
      "\n",
      "Random Forests\n",
      "best score: 0.9097496012759171\n",
      "best parameters: {'bootstrap': False, 'min_samples_split': 5, 'n_estimators': 100, 'random_state': 42}\n",
      "best accuracy (validation): 0.9674418604651163\n",
      "best f1_macro (validation): 0.9219758694349925\n",
      "Verified\n",
      "Classification Report (Test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       163\n",
      "           1       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.94       185\n",
      "   macro avg       0.97      0.75      0.82       185\n",
      "weighted avg       0.94      0.94      0.93       185\n",
      "\n",
      "\n",
      "Naive Bayes\n",
      "best score: 0.8354992025518342\n",
      "best parameters: {}\n",
      "best accuracy (validation): 0.9325581395348838\n",
      "best f1_macro (validation): 0.8342626682909593\n",
      "Verified\n",
      "Classification Report (Test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.22      0.35       163\n",
      "           1       0.12      0.77      0.20        22\n",
      "\n",
      "    accuracy                           0.29       185\n",
      "   macro avg       0.50      0.50      0.28       185\n",
      "weighted avg       0.79      0.29      0.34       185\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Init the grid search for each model\n",
    "grid_search_svc = GridSearchCV(\n",
    "    model_svc,\n",
    "    params_svc,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True,\n",
    "    refit='bal_accuracy',\n",
    "    n_jobs=JOB_NUM\n",
    ")\n",
    "\n",
    "grid_search_decision_tree = GridSearchCV(\n",
    "    model_decision_tree,\n",
    "    params_decision_tree,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True,\n",
    "    refit='bal_accuracy',\n",
    "    n_jobs=JOB_NUM\n",
    ")\n",
    "\n",
    "grid_search_random_forests = GridSearchCV(\n",
    "    model_random_forests,\n",
    "    params_random_forests,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True,\n",
    "    refit='bal_accuracy',\n",
    "    n_jobs=JOB_NUM\n",
    ")\n",
    "\n",
    "grid_search_naive_bayes = GridSearchCV(\n",
    "    model_naive_bayes,\n",
    "    params_naive_bayes,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True,\n",
    "    refit='bal_accuracy',\n",
    "    n_jobs=JOB_NUM\n",
    ")\n",
    "\n",
    "grid_search_list = [\n",
    "    {\n",
    "        'model_name': 'Support Vector Machine',\n",
    "        'grid_search': grid_search_svc\n",
    "    },\n",
    "    {\n",
    "        'model_name': 'Decision Tree',\n",
    "        'grid_search': grid_search_decision_tree\n",
    "    },\n",
    "    {\n",
    "        'model_name': 'Random Forests',\n",
    "        'grid_search': grid_search_random_forests\n",
    "    },\n",
    "    {\n",
    "        'model_name': 'Naive Bayes',\n",
    "        'grid_search': grid_search_naive_bayes\n",
    "    }\n",
    "]\n",
    "\n",
    "# print table data\n",
    "print_table_data(grid_search_list, train_data_prepared, labels, test_data_prepared, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a table format, report the train and test results you have obtained for all 4 models. Your table must include the following columns: (6)\n",
    "- model\n",
    "- best parameters (validation)\n",
    "- best accuracy (validation)\n",
    "- best f1_macro (validation)\n",
    "- best accuracy (test)\n",
    "- best f1_macro (test)\n",
    "\n",
    "**Answer**:\n",
    "|model|best parameters|best accuracy(validation)|best f1_macro(validation)|best accuracy (test)|best f1_macro (test)\n",
    "|-----|-----|-----|-----|-----|-----|\n",
    "|Support Vector Machine|{'gamma': 'scale', 'kernel': 'rbf'}|0.9116279069767442|0.7153030807615023|0.93|0.77\n",
    "|Decision Tree|{'min_samples_leaf': 20, 'min_samples_split': 5}|0.9511627906976743|0.8791111379160915|0.94|0.83\n",
    "|Random Forests|{'bootstrap': False, 'min_samples_split': 5, 'n_estimators': 100, 'random_state': 42}|0.9674418604651163|0.9219758694349925|0.94|0.82\n",
    "|Naive Bayes|{}|0.9325581395348838|0.8342626682909593|0.29|0.28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling data imbalance (18/100)\n",
    "Given the dataset that can be considered as having an imbalance, we can use different data augmentation strategies based on the minority class.\n",
    "In this section, you will be given the task of oversampling the dataset using the Imbalanced-Learn Library. \n",
    "\n",
    "Please install the imbalanced-learn library using the following command:\n",
    "* conda install -c conda-forge imbalanced-learnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (430, 14)\n",
      "Oversampled dataset shape: (754, 14)\n",
      "Class distribution in the oversampled dataset:\n",
      " 0    377\n",
      "1    377\n",
      "Name: category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# create the oversampling object\n",
    "oversample = SMOTE()\n",
    "# oversample the minority class\n",
    "# input_x will be the transformed training data using the combined pipelines, and the labels represent the training labels\n",
    "input_x = train_data_prepared\n",
    "input_x_over, y_over = oversample.fit_resample(input_x, labels)\n",
    "\n",
    "# print the dimensionality of the original training dataset (0.5)\n",
    "print(f\"Original dataset shape: {input_x.shape}\")\n",
    "\n",
    "# print the dimensionality of the oversampled dataset (0.5)\n",
    "print(f\"Oversampled dataset shape: {input_x_over.shape}\")\n",
    "\n",
    "# print the new class distribution using the Counter (1)\n",
    "print(f\"Class distribution in the oversampled dataset:\\n {y_over.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'bootstrap': False, 'min_samples_split': 5, 'n_estimators': 100, 'random_state': 42}\n",
      "Best estimator: RandomForestClassifier(bootstrap=False, min_samples_split=5, random_state=42)\n",
      "Best score: 0.988017543859649\n"
     ]
    }
   ],
   "source": [
    "# initialize the same models as before with their default hyperparameters (1)\n",
    "# Support Vector Machine\n",
    "model_svc = SVC()\n",
    "# Decision Trees\n",
    "model_decision_tree = DecisionTreeClassifier()\n",
    "# Random Forests\n",
    "model_random_forests = RandomForestClassifier()\n",
    "# Naive Bayes\n",
    "model_naive_bayes = GaussianNB()\n",
    "\n",
    "# initialize gridsearch with the required parameters as used before (2)\n",
    "grid_search_random_forests = GridSearchCV(\n",
    "    model_random_forests,\n",
    "    params_random_forests,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True,\n",
    "    refit='bal_accuracy',\n",
    "    n_jobs=JOB_NUM\n",
    ")\n",
    "\n",
    "# fit the oversampled training data (0.5)\n",
    "grid_search_random_forests.fit(input_x_over, y_over)\n",
    "\n",
    "# print the best parameters (0.5)\n",
    "print(f\"Best parameters: {grid_search_random_forests.best_params_}\")\n",
    "\n",
    "# print the best estimator (0.5)\n",
    "print(f\"Best estimator: {grid_search_random_forests.best_estimator_}\")\n",
    "\n",
    "# print the best score from trained GridSearchCV model (0.5)\n",
    "print(f\"Best score: {grid_search_random_forests.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       163\n",
      "           1       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.94       185\n",
      "   macro avg       0.97      0.73      0.79       185\n",
      "weighted avg       0.94      0.94      0.92       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# obtain predictions on test data using the best model from GridSearchCV above (i.e., .best_estimator_) (2)\n",
    "test_predictions = grid_search_random_forests.best_estimator_.predict(test_data_prepared)\n",
    "\n",
    "# generate the classification report and the confusion matrix for test predictions (3)\n",
    "classification_report_test = classification_report(test_labels, test_predictions)\n",
    "print(f\"Classification Report (Test):\\n {classification_report_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine\n",
      "best score: 0.9522456140350878\n",
      "best parameters: {'gamma': 'scale', 'kernel': 'rbf'}\n",
      "best accuracy (validation): 0.9522295805739516\n",
      "best f1_macro (validation): 0.9522074858401842\n",
      "Verified\n",
      "Classification Report (Test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       163\n",
      "           1       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.94       185\n",
      "   macro avg       0.97      0.73      0.79       185\n",
      "weighted avg       0.94      0.94      0.92       185\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "best score: 0.938859649122807\n",
      "best parameters: {'min_samples_leaf': 10, 'min_samples_split': 5}\n",
      "best accuracy (validation): 0.9389845474613686\n",
      "best f1_macro (validation): 0.9389268978138665\n",
      "Verified\n",
      "Classification Report (Test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       163\n",
      "           1       1.00      0.55      0.71        22\n",
      "\n",
      "    accuracy                           0.95       185\n",
      "   macro avg       0.97      0.77      0.84       185\n",
      "weighted avg       0.95      0.95      0.94       185\n",
      "\n",
      "\n",
      "Random Forests\n",
      "best score: 0.988017543859649\n",
      "best parameters: {'bootstrap': False, 'min_samples_split': 5, 'n_estimators': 100, 'random_state': 42}\n",
      "best accuracy (validation): 0.9880353200883002\n",
      "best f1_macro (validation): 0.988034094180511\n",
      "Verified\n",
      "Classification Report (Test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       163\n",
      "           1       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.94       185\n",
      "   macro avg       0.97      0.73      0.79       185\n",
      "weighted avg       0.94      0.94      0.92       185\n",
      "\n",
      "\n",
      "Naive Bayes\n",
      "best score: 0.8448771929824561\n",
      "best parameters: {}\n",
      "best accuracy (validation): 0.8448388520971303\n",
      "best f1_macro (validation): 0.8428707283719705\n",
      "Verified\n",
      "Classification Report (Test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.27      0.42       163\n",
      "           1       0.12      0.77      0.22        22\n",
      "\n",
      "    accuracy                           0.33       185\n",
      "   macro avg       0.51      0.52      0.32       185\n",
      "weighted avg       0.81      0.33      0.39       185\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Init the grid search for each model\n",
    "grid_search_svc = GridSearchCV(\n",
    "    model_svc,\n",
    "    params_svc,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True,\n",
    "    refit='bal_accuracy',\n",
    "    n_jobs=JOB_NUM\n",
    ")\n",
    "\n",
    "grid_search_decision_tree = GridSearchCV(\n",
    "    model_decision_tree,\n",
    "    params_decision_tree,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True,\n",
    "    refit='bal_accuracy',\n",
    "    n_jobs=JOB_NUM\n",
    ")\n",
    "\n",
    "grid_search_random_forests = GridSearchCV(\n",
    "    model_random_forests,\n",
    "    params_random_forests,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True,\n",
    "    refit='bal_accuracy',\n",
    "    n_jobs=JOB_NUM\n",
    ")\n",
    "\n",
    "grid_search_naive_bayes = GridSearchCV(\n",
    "    model_naive_bayes,\n",
    "    params_naive_bayes,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True,\n",
    "    refit='bal_accuracy',\n",
    "    n_jobs=JOB_NUM\n",
    ")\n",
    "\n",
    "grid_search_list = [\n",
    "    {\n",
    "        'model_name': 'Support Vector Machine',\n",
    "        'grid_search': grid_search_svc\n",
    "    },\n",
    "    {\n",
    "        'model_name': 'Decision Tree',\n",
    "        'grid_search': grid_search_decision_tree\n",
    "    },\n",
    "    {\n",
    "        'model_name': 'Random Forests',\n",
    "        'grid_search': grid_search_random_forests\n",
    "    },\n",
    "    {\n",
    "        'model_name': 'Naive Bayes',\n",
    "        'grid_search': grid_search_naive_bayes\n",
    "    }\n",
    "]\n",
    "\n",
    "# print table data with the oversampled dataset\n",
    "print_table_data(grid_search_list, input_x_over, y_over, test_data_prepared, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a table format, report the train and test results you have obtained for all 4 models. Your table must include the following columns: (6)\n",
    "- model\n",
    "- best parameters (validation)\n",
    "- best accuracy (validation)\n",
    "- best f1_macro (validation)\n",
    "- best accuracy (test)\n",
    "- best f1_macro (test)\n",
    "\n",
    "**Answer**:\n",
    "|model|best parameters|best accuracy(validation)|best f1_macro(validation)|best accuracy (test)|best f1_macro (test)\n",
    "|-----|-----|-----|-----|-----|-----|\n",
    "|Support Vector Machine|{'gamma': 'scale', 'kernel': 'rbf'}|0.9522295805739516|0.9522074858401842|0.94|0.79\n",
    "|Decision Tree|{'min_samples_leaf': 10, 'min_samples_split': 5}|0.9389845474613686|0.9389268978138665|0.95|0.84\n",
    "|Random Forests|{'bootstrap': False, 'min_samples_split': 5, 'n_estimators': 100, 'random_state': 42}|0.9880353200883002|0.988034094180511|0.94|0.79\n",
    "|Naive Bayes|{}|0.8448388520971303|0.8428707283719705|0.33|0.32"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcacb1169d0317e97b762e0c1a317633c556cb59cb1017287d7e24b96b766e04"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('csi4106')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
